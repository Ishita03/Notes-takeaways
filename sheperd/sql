Argus Java Payload : {"action":{"action_type":"SparkSubmit","language":{"language_type":"Java","jar":"https://binrepo.target.com/artifactory/price-insights/stg/competitor_price_history_store/competitor_market_signals_dpp_3.5.1-2.13.08.jar","main_class":"com.tgt.dsc.price.pricehistory.compstore.PipeLineInvoker","application_arguments":["stg_application.conf","2024-10-12","NA"]},"jars":[],"files":["hdfs://bigred3ns/user/SVPRIHDS/priceinsights/stg/log4j.properties","https://binrepo.target.com/artifactory/price-insights/stg/competitor_price_history_store/stg_application.conf"],"archives":[],"repositories":[],"packages":[],"exclude-packages":[],"executor-memory":"10g","executor-cores":1,"num-executors":5,"properties-file":"","driver-memory":"8g","driver-cores":1,"driver-class-path":[],"driver-java-options":[],"driver-library-path":[],"conf":{"spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version":"2","spark.sql.legacy.timeParserPolicy":"LEGACY","spark.hadoop.mapred.output.committer.class":"org.apache.hadoop.mapred.FileOutputCommitter","spark.sql.hive.metastorePartitionPruningFallbackOnException":"true","spark.yarn.tags":"SHEPHERD"}}}

Argus Java Payload : {"action":{"action_type":"SparkSubmit","language":{"language_type":"Java","jar":"https://binrepo.target.com/artifactory/price-insights/prd/competitor_price_history_store/competitor_market_signals_dpp_3.5.1-2.13.08.jar ","main_class":"com.tgt.dsc.price.pricehistory.compstore.PipeLineInvoker","application_arguments":["prd_application.conf","2024-10-12","NA"]},"jars":[],"files":["hdfs://bigred3ns/user/SVPRIHDP/priceinsights/prd/log4j.properties","https://binrepo.target.com/artifactory/price-insights/prd/competitor_price_history_store/prd_application.conf"],"archives":[],"repositories":[],"packages":[],"exclude-packages":[],"executor-memory":"8g","executor-cores":1,"num-executors":5,"properties-file":"","driver-memory":"1G","driver-cores":1,"driver-class-path":[],"driver-java-options":[],"driver-library-path":[],"conf":{"spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version":"2","spark.hadoop.mapred.output.committer.class":"org.apache.hadoop.mapred.FileOutputCommitter","spark.yarn.tags":"SHEPHERD"}}}

val df = spark.read.table("stg_priceent_fnd.omnichannel_competitor_price_history").where("retail_day_d">'2024-09-15')

df4.coalesce(2).write.format("orc").mode("Overwrite")
.partitionBy("retail_day_d","retailer_short_n","channel_n")
.save("/user/SVPRIHDP/hive/external/tmp/store")

MSCK REPAIR TABLE $finalTable
df4.coalesce(2).write.format("orc").mode("Overwrite").insertInto("stg_priceent_fnd.omnichannel_competitor_price_history")